{"metadata": {"kernelspec": {"display_name": "Python 2", "language": "python", "name": "python2"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "version": "2.7.10"}}, "nbformat": 4, "nbformat_minor": 0, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Planet: Understanding the Amazon deforestation from Space challenge"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Special thanks to the kernel contributors of this challenge (especially @anokas and @Kaggoo) who helped me find a starting point for this notebook.\n", "\n", "The whole code including the `data_helper.py` and `keras_helper.py` files are available on github [here](https://github.com/EKami/planet-amazon-deforestation) and the notebook can be found on the same github [here](https://github.com/EKami/planet-amazon-deforestation/blob/master/notebooks/amazon_forest_notebook.ipynb)\n", "\n", "**If you found this notebook useful some upvotes would be greatly appreciated! :) **"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Start by adding the helper files to the python path"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"collapsed": false}, "outputs": [], "source": ["import sys\n", "\n", "sys.path.append('../src')\n", "sys.path.append('../tests')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Import required modules"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"collapsed": false}, "outputs": [], "source": ["import os\n", "import gc\n", "import bcolz\n", "import numpy as np\n", "import pandas as pd\n", "import seaborn as sns\n", "import tensorflow as tf\n", "import matplotlib.pyplot as plt\n", "import matplotlib.image as mpimg\n", "from keras.optimizers import Adam\n", "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, History\n", "import vgg16\n", "import data_helper\n", "from data_helper import AmazonPreprocessor\n", "from kaggle_data.downloader import KaggleDataDownloader\n", "\n", "%matplotlib inline\n", "%config InlineBackend.figure_format = 'retina'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print tensorflow version for reuse (the Keras module is used directly from the tensorflow framework)"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"collapsed": false}, "outputs": [], "source": ["tf.__version__"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Download the competition files\n", "Download the dataset files and extract them automatically with the help of [Kaggle data downloader](https://github.com/EKami/kaggle-data-downloader)"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"collapsed": false}, "outputs": [], "source": ["competition_name = \"planet-understanding-the-amazon-from-space\"\n", "\n", "train, train_u = \"train-jpg.tar.7z\", \"train-jpg.tar\"\n", "test, test_u = \"test-jpg.tar.7z\", \"test-jpg.tar\"\n", "test_additional, test_additional_u = \"test-jpg-additional.tar.7z\", \"test-jpg-additional.tar\"\n", "test_labels = \"train_v2.csv.zip\"\n", "destination_path = \"../input/\"\n", "is_datasets_present = False\n", "\n", "# If the folders already exists then the files may already be extracted\n", "# This is a bit hacky but it's sufficient for our needs\n", "datasets_path = data_helper.get_jpeg_data_files_paths()\n", "for dir_path in datasets_path:\n", "    if os.path.exists(dir_path):\n", "        is_datasets_present = True\n", "\n", "if not is_datasets_present:\n", "    # Put your Kaggle user name and password in a $KAGGLE_USER and $KAGGLE_PASSWD env vars respectively\n", "    downloader = KaggleDataDownloader(os.getenv(\"KAGGLE_USER\"), os.getenv(\"KAGGLE_PASSWD\"), competition_name)\n", "    \n", "    train_output_path = downloader.download_dataset(train, destination_path)\n", "    downloader.decompress(train_output_path, destination_path) # Outputs a tar file\n", "    downloader.decompress(destination_path + train_u, destination_path) # Extract the content of the previous tar file\n", "    os.remove(train_output_path) # Removes the 7z file\n", "    os.remove(destination_path + train_u) # Removes the tar file\n", "    \n", "    test_output_path = downloader.download_dataset(test, destination_path)\n", "    downloader.decompress(test_output_path, destination_path) # Outputs a tar file\n", "    downloader.decompress(destination_path + test_u, destination_path) # Extract the content of the previous tar file\n", "    os.remove(test_output_path) # Removes the 7z file\n", "    os.remove(destination_path + test_u) # Removes the tar file\n", "    \n", "    test_add_output_path = downloader.download_dataset(test_additional, destination_path)\n", "    downloader.decompress(test_add_output_path, destination_path) # Outputs a tar file\n", "    downloader.decompress(destination_path + test_additional_u, destination_path) # Extract the content of the previous tar file\n", "    os.remove(test_add_output_path) # Removes the 7z file\n", "    os.remove(destination_path + test_additional_u) # Removes the tar file\n", "    \n", "    test_labels_output_path = downloader.download_dataset(test_labels, destination_path)\n", "    downloader.decompress(test_labels_output_path, destination_path) # Outputs a csv file\n", "    os.remove(test_labels_output_path) # Removes the zip file\n", "else:\n", "    print(\"All datasets are present.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Inspect image labels\n", "Visualize what the training set looks like"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"collapsed": false}, "outputs": [], "source": ["train_jpeg_dir, test_jpeg_dir, test_jpeg_additional, train_csv_file = data_helper.get_jpeg_data_files_paths()\n", "labels_df = pd.read_csv(train_csv_file)\n", "labels_df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Each image can be tagged with multiple tags, lets list all uniques tags"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"collapsed": false}, "outputs": [], "source": ["# Print all unique tags\n", "from itertools import chain\n", "labels_list = list(chain.from_iterable([tags.split(\" \") for tags in labels_df['tags'].values]))\n", "labels_set = set(labels_list)\n", "print(\"There is {} unique labels including {}\".format(len(labels_set), labels_set))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Repartition of each labels"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"collapsed": false}, "outputs": [], "source": ["# Histogram of label instances\n", "labels_s = pd.Series(labels_list).value_counts() # To sort them by count\n", "fig, ax = plt.subplots(figsize=(16, 8))\n", "sns.barplot(x=labels_s, y=labels_s.index, orient='h')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Images\n", "Visualize some chip images to know what we are dealing with.\n", "Lets vizualise 1 chip for the 17 images to get a sense of their differences."]}, {"cell_type": "code", "execution_count": 8, "metadata": {"collapsed": false}, "outputs": [], "source": ["images_title = [labels_df[labels_df['tags'].str.contains(label)].iloc[i]['image_name'] + '.jpg' \n", "                for i, label in enumerate(labels_set)]\n", "\n", "plt.rc('axes', grid=False)\n", "_, axs = plt.subplots(5, 4, sharex='col', sharey='row', figsize=(15, 20))\n", "axs = axs.ravel()\n", "\n", "for i, (image_name, label) in enumerate(zip(images_title, labels_set)):\n", "    img = mpimg.imread(train_jpeg_dir + '/' + image_name)\n", "    axs[i].imshow(img)\n", "    axs[i].set_title('{} - {}'.format(image_name, label))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Image resize & validation split\n", "Define the dimensions of the image data trained by the network. Recommended resized images could be 32x32, 64x64, or 128x128 to speedup the training. \n", "\n", "You could also use `None` to use full sized images.\n", "\n", "Be careful, the higher the `validation_split_size` the more RAM you will consume."]}, {"cell_type": "code", "execution_count": 9, "metadata": {"collapsed": false}, "outputs": [], "source": ["img_resize = (128, 128) # The resize size of each image ex: (64, 64) or None to use the default image size\n", "validation_split_size = 0.2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Data preprocessing\n", "Due to the hudge amount of memory the preprocessed images can take, we will create a dedicated `AmazonPreprocessor` class which job is to preprocess the data right in time at specific steps (training/inference) so that our RAM don't get completely filled by the preprocessed images. \n", "\n", "The only exception to this being the validation dataset as we need to use it as-is for f2 score calculation as well as when we calculate the validation accuracy of each batch."]}, {"cell_type": "code", "execution_count": 10, "metadata": {"collapsed": false}, "outputs": [], "source": ["preprocessor = AmazonPreprocessor(train_jpeg_dir, train_csv_file, test_jpeg_dir, test_jpeg_additional, \n", "                                  img_resize, validation_split_size)\n", "preprocessor.init()"]}, {"cell_type": "code", "execution_count": 11, "metadata": {"collapsed": false}, "outputs": [], "source": ["print(\"X_train/y_train length: {}/{}\".format(len(preprocessor.X_train), len(preprocessor.y_train)))\n", "print(\"X_val/y_val length: {}/{}\".format(len(preprocessor.X_val), len(preprocessor.y_val)))\n", "print(\"X_test/X_test_filename length: {}/{}\".format(len(preprocessor.X_test), len(preprocessor.X_test_filename)))\n", "preprocessor.y_map"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Funetuning\n", "\n", "Here we define the model for finetuning"]}, {"cell_type": "code", "execution_count": 12, "metadata": {"collapsed": false}, "outputs": [], "source": ["model = vgg16.create_model(img_dim=(128, 128, 3))\n", "model.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Fine-tune conv layers\n", "We will now finetune all layers in the VGG16 model. "]}, {"cell_type": "code", "execution_count": 13, "metadata": {"collapsed": false}, "outputs": [], "source": ["history = History()\n", "callbacks = [history, \n", "             EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n", "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=0, min_lr=1e-7, verbose=1),\n", "             ModelCheckpoint(filepath='weights/weights.best.hdf5', verbose=1, save_best_only=True, \n", "                             save_weights_only=True, mode='auto')]\n", "\n", "X_train, y_train = preprocessor.X_train, preprocessor.y_train\n", "X_val, y_val = preprocessor.X_val, preprocessor.y_val\n", "\n", "batch_size = 128\n", "train_generator = preprocessor.get_train_generator(batch_size)\n", "steps = len(X_train) / batch_size\n", "\n", "model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics = ['accuracy'])\n", "history = model.fit_generator(train_generator, steps, epochs=25, verbose=1, \n", "                    validation_data=(X_val, y_val), callbacks=callbacks)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Visualize Loss Curve"]}, {"cell_type": "code", "execution_count": 14, "metadata": {"collapsed": false}, "outputs": [], "source": ["plt.plot(history.history['loss'])\n", "plt.plot(history.history['val_loss'])\n", "plt.title('model loss')\n", "plt.ylabel('loss')\n", "plt.xlabel('epoch')\n", "plt.legend(['train', 'validation'], loc='upper left')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Best Weights"]}, {"cell_type": "code", "execution_count": 15, "metadata": {"collapsed": false}, "outputs": [], "source": ["model.load_weights(\"weights/weights.best.hdf5\")\n", "print(\"Weights loaded\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Check Fbeta Score"]}, {"cell_type": "code", "execution_count": 16, "metadata": {"collapsed": false}, "outputs": [], "source": ["fbeta_score = vgg16.fbeta(model, X_val, y_val)\n", "\n", "fbeta_score"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Make predictions"]}, {"cell_type": "code", "execution_count": 17, "metadata": {"collapsed": false}, "outputs": [], "source": ["predictions, x_test_filename = vgg16.predict(model, preprocessor, batch_size=128)\n", "print(\"Predictions shape: {}\\nFiles name shape: {}\\n1st predictions ({}) entry:\\n{}\".format(predictions.shape, \n", "                                                                              x_test_filename.shape,\n", "                                                                              x_test_filename[0], predictions[0]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Before mapping our predictions to their appropriate labels we need to figure out what threshold to take for each class"]}, {"cell_type": "code", "execution_count": 18, "metadata": {"collapsed": false}, "outputs": [], "source": ["thresholds = [0.2] * len(labels_set)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now lets map our predictions to their tags by using the thresholds"]}, {"cell_type": "code", "execution_count": 19, "metadata": {"collapsed": false}, "outputs": [], "source": ["predicted_labels = vgg16.map_predictions(preprocessor, predictions, thresholds)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally lets assemble and visualize our predictions for the test dataset"]}, {"cell_type": "code", "execution_count": 20, "metadata": {"collapsed": false}, "outputs": [], "source": ["tags_list = [None] * len(predicted_labels)\n", "for i, tags in enumerate(predicted_labels):\n", "    tags_list[i] = ' '.join(map(str, tags))\n", "\n", "final_data = [[filename.split(\".\")[0], tags] for filename, tags in zip(x_test_filename, tags_list)]"]}, {"cell_type": "code", "execution_count": 21, "metadata": {"collapsed": false}, "outputs": [], "source": ["final_df = pd.DataFrame(final_data, columns=['image_name', 'tags'])\n", "print(\"Predictions rows:\", final_df.size)\n", "final_df.head()"]}, {"cell_type": "code", "execution_count": 22, "metadata": {"collapsed": false}, "outputs": [], "source": ["tags_s = pd.Series(list(chain.from_iterable(predicted_labels))).value_counts()\n", "fig, ax = plt.subplots(figsize=(16, 8))\n", "sns.barplot(x=tags_s, y=tags_s.index, orient='h');"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If there is a lot of `primary` and `clear` tags, this final dataset may be legit..."]}, {"cell_type": "markdown", "metadata": {}, "source": ["And save it to a submission file"]}, {"cell_type": "code", "execution_count": 23, "metadata": {"collapsed": false}, "outputs": [], "source": ["final_df.to_csv('../submission_file.csv', index=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### That's it, we're done!"]}]}